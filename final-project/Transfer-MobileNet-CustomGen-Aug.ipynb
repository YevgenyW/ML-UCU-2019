{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test', 'train_labels.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob \n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import cv2\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.preprocessing.image import img_to_array as img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img as load_img\n",
    "\n",
    "def readImage(path, target_size):   \n",
    "    return img_to_array(load_img(path, target_size=target_size))/255.\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(96,96), n_channels=1,\n",
    "                 n_classes=10, shuffle=True, augmentation = True):\n",
    "        'Initialization'\n",
    "    \n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "        num = self.labels.shape[0] - (self.labels.shape[0] % batch_size)\n",
    "        self.classes = self.labels.iloc[:num].values\n",
    "        if (self.augmentation == True):\n",
    "            print(\"Data augmentation enabled\")\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        \n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "       \n",
    "        list_IDs_temp = [self.list_IDs.iloc[k] for k in indexes]\n",
    "        list_labels_temp = [self.labels.iloc[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp, list_labels_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp, list_labels_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        \n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels), dtype=np.uint8)\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        # Generate data\n",
    "\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            path = \"../input/train/\" + ID + \".tif\"\n",
    "            X[i,] = readImage(path,self.dim)\n",
    "\n",
    "            # Store class\n",
    "            y[i] = list_labels_temp[i]\n",
    "\n",
    "        if (self.augmentation == True):\n",
    "            X = self.augment(X)\n",
    "        # y_out = keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "    \n",
    "        return X, y\n",
    "\n",
    "    def augment(self, images, show = False):\n",
    "        'Images augmentation'\n",
    "        # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "        # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "        # Define our sequence of augmentation steps that will be applied to every image\n",
    "        # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "        # in 50% of all cases. In all other cases they will sample new values\n",
    "        # _per channel_.\n",
    "        seq = iaa.Sequential(\n",
    "            [\n",
    "                # apply the following augmenters to most images\n",
    "                iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "                iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "                # crop images by -5% to 10% of their height/width\n",
    "                sometimes(iaa.CropAndPad(\n",
    "                    percent=(-0.05, 0.1),\n",
    "                    pad_mode=ia.ALL,\n",
    "                    pad_cval=(0, 255)\n",
    "                )),\n",
    "                sometimes(iaa.Affine(\n",
    "                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "                    rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "                    shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "                    order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "                    cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                    mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "                )),\n",
    "                # execute 0 to 5 of the following (less important) augmenters per image\n",
    "                # don't execute all of them, as that would often be way too strong\n",
    "                iaa.SomeOf((0, 5),\n",
    "                    [\n",
    "                        sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                        iaa.OneOf([\n",
    "                            iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                            iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                            iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                        ]),\n",
    "                        iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                        iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                        # search either for all edges or for directed edges,\n",
    "                        # blend the result with the original image using a blobby mask\n",
    "                        iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                            iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                            iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                        ])),\n",
    "                        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                            iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                        ]),\n",
    "                        iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                        iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                        iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
    "                        # either change the brightness of the whole image (sometimes\n",
    "                        # per channel) or change the brightness of subareas\n",
    "                        iaa.OneOf([\n",
    "                            iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                            iaa.FrequencyNoiseAlpha(\n",
    "                                exponent=(-4, 0),\n",
    "                                first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
    "                                second=iaa.ContrastNormalization((0.5, 2.0))\n",
    "                            )\n",
    "                        ]),\n",
    "                        iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                        iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                        sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                        sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                        sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "                    ],\n",
    "                    random_order=True\n",
    "                )\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "        \n",
    "        if (show == True):\n",
    "            # show an image with 8*8 augmented versions of image 0\n",
    "            seq.show_grid(images[0], cols=8, rows=8)\n",
    "        \n",
    "        return seq.augment_images(images)\n",
    "\n",
    "    #def classes(self):\n",
    "     #   return self.labels.iloc[:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_RATIO = 0.85\n",
    "IMAGE_SIZE = 128\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 192\n",
    "VERBOSITY = 1\n",
    "TESTING_BATCH_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('../input/train_labels.csv')\n",
    "print(data['label'].value_counts())\n",
    "training_data, validation_data = train_test_split(data, train_size=TRAINING_RATIO, stratify=data['label'])\n",
    "print(training_data['label'].value_counts())\n",
    "print(validation_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (IMAGE_SIZE, IMAGE_SIZE),\n",
    "          'batch_size': BATCH_SIZE,\n",
    "          'n_classes': 2,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'augmentation': True}\n",
    "\n",
    "training_generator = DataGenerator(training_data.id, training_data.label, **params)\n",
    "validation_generator = DataGenerator(validation_data.id, validation_data.label, **params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=MobileNet(weights='imagenet',include_top=False,\n",
    "                    input_shape=(128,128,3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(1,activation='sigmoid')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    # steps_per_epoch=2,\n",
    "                    validation_data=validation_generator, \n",
    "                    #validation_steps=3,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=6,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_files = glob(os.path.join('../input/test/','*.tif'))\n",
    "submission = pd.DataFrame()\n",
    "for index in range(0, len(testing_files), TESTING_BATCH_SIZE):\n",
    "    data_frame = pd.DataFrame({'path': testing_files[index:index+TESTING_BATCH_SIZE]})\n",
    "    data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "    data_frame['image'] = data_frame['path'].map(lambda x: readImage(x, (IMAGE_SIZE,IMAGE_SIZE)))\n",
    "    images = np.stack(data_frame.image, axis=0)\n",
    "    predicted_labels = [model.predict(np.expand_dims(image, axis=0))[0][0] for image in images]\n",
    "    predictions = np.array(predicted_labels)\n",
    "    data_frame['label'] = predictions\n",
    "    submission = pd.concat([submission, data_frame[[\"id\", \"label\"]]])\n",
    "submission.to_csv(\"mobilenet_custom_aug.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
