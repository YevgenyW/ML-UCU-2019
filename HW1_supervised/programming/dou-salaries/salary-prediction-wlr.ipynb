{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Передбачення зарплат на IT-ринку України"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У цьому завданні ви працюватимете з реальними даними з [зарплатного опитування DOU.ua за травень 2016р](https://dou.ua/lenta/articles/salary-report-may-june-2016/). Ви реалізуєте зважену лінійну регресію, яка передбачає зарплати Java-інженерів, та навчите свою модель за допомогою градієнтного спуску.\n",
    "\n",
    "Заповніть пропущений код в розділі «Моделювання» (позначено коментарями) та запустіть розділ «Тестування», щоб перевірити його правильність."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:11.383992Z",
     "start_time": "2019-02-17T20:50:11.381168Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:11.592070Z",
     "start_time": "2019-02-17T20:50:11.589441Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:11.834519Z",
     "start_time": "2019-02-17T20:50:11.830706Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:12.067332Z",
     "start_time": "2019-02-17T20:50:12.063639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ipython_unittest extension is already loaded. To reload it, use:\n",
      "  %reload_ext ipython_unittest\n"
     ]
    }
   ],
   "source": [
    "%load_ext ipython_unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Підготовка даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:12.696127Z",
     "start_time": "2019-02-17T20:50:12.638234Z"
    }
   },
   "outputs": [],
   "source": [
    "df_salaries = pd.read_csv(\"data/2016_may_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оберемо тільки Java-інженерів з-поміж усіх респондентів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:13.446339Z",
     "start_time": "2019-02-17T20:50:13.438741Z"
    }
   },
   "outputs": [],
   "source": [
    "df_java = pd.DataFrame(df_salaries[(df_salaries[\"Язык.программирования\"] == \"Java\") &\n",
    "                                   (df_salaries[\"cls\"] == \"DEV\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейменуємо деякі колонки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:14.337511Z",
     "start_time": "2019-02-17T20:50:14.333208Z"
    }
   },
   "outputs": [],
   "source": [
    "df_java.rename(\n",
    "    columns={\n",
    "        \"exp\": \"TotalExperience\",\n",
    "        \"loc\": \"Location\"\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодуємо рівень англійської мови числами від 1 (найнижчий) до 5 (найвищий):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:15.282564Z",
     "start_time": "2019-02-17T20:50:15.277361Z"
    }
   },
   "outputs": [],
   "source": [
    "df_java[\"EnglishLevel\"] = df_java[\"Уровень.английского\"].map({\n",
    "    \"элементарный\": 1,\n",
    "    \"ниже среднего\": 2,\n",
    "    \"средний\": 3,\n",
    "    \"выше среднего\": 4,\n",
    "    \"продвинутый\": 5\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодуємо колонку Location (найбільші IT-міста або \"other\") за допомогою one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:16.494303Z",
     "start_time": "2019-02-17T20:50:16.486023Z"
    }
   },
   "outputs": [],
   "source": [
    "city_columns = [\n",
    "    \"LocationOther\",\n",
    "    \"LocationDnipro\",\n",
    "    \"LocationKyiv\",\n",
    "    \"LocationLviv\",\n",
    "    \"LocationOdesa\",\n",
    "    \"LocationKharkiv\"\n",
    "]\n",
    "df_java[city_columns] = pd.get_dummies(df_java[\"Location\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Відберемо такі ознаки:\n",
    "\n",
    "* Загальна кількість років досвіду\n",
    "* Рівень англійської мови\n",
    "* Місто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:50:17.461347Z",
     "start_time": "2019-02-17T20:50:17.454453Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = [\"TotalExperience\", \"EnglishLevel\"] + city_columns\n",
    "df_X = df_java[feature_columns]\n",
    "df_y = df_java[[\"salary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.451488Z",
     "start_time": "2019-02-17T20:44:15.448298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (929, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.469161Z",
     "start_time": "2019-02-17T20:44:15.453470Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalExperience</th>\n",
       "      <th>EnglishLevel</th>\n",
       "      <th>LocationOther</th>\n",
       "      <th>LocationDnipro</th>\n",
       "      <th>LocationKyiv</th>\n",
       "      <th>LocationLviv</th>\n",
       "      <th>LocationOdesa</th>\n",
       "      <th>LocationKharkiv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TotalExperience  EnglishLevel  LocationOther  LocationDnipro  \\\n",
       "5               0.5             3              1               0   \n",
       "7               5.0             1              0               0   \n",
       "17              0.0             3              0               0   \n",
       "27              4.0             3              0               0   \n",
       "28              6.0             4              0               0   \n",
       "39              3.0             4              0               1   \n",
       "46              2.0             4              0               0   \n",
       "49              3.0             3              0               0   \n",
       "59              2.0             3              0               0   \n",
       "89              1.0             5              0               0   \n",
       "\n",
       "    LocationKyiv  LocationLviv  LocationOdesa  LocationKharkiv  \n",
       "5              0             0              0                0  \n",
       "7              1             0              0                0  \n",
       "17             1             0              0                0  \n",
       "27             1             0              0                0  \n",
       "28             1             0              0                0  \n",
       "39             0             0              0                0  \n",
       "46             0             0              0                1  \n",
       "49             1             0              0                0  \n",
       "59             0             0              0                1  \n",
       "89             1             0              0                0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.478249Z",
     "start_time": "2019-02-17T20:44:15.470945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salary\n",
       "5      500\n",
       "7     1600\n",
       "17     600\n",
       "27    3400\n",
       "28    2880\n",
       "39    1425\n",
       "46    1700\n",
       "49    1800\n",
       "59    1235\n",
       "89    1200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розділимо вибірку на навчальну та тестову:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.482263Z",
     "start_time": "2019-02-17T20:44:15.480040Z"
    }
   },
   "outputs": [],
   "source": [
    "training_set_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.491667Z",
     "start_time": "2019-02-17T20:44:15.484147Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_assignment = np.random.uniform(size=len(df_X))\n",
    "\n",
    "X_train = df_X[dataset_assignment <= training_set_size].values\n",
    "y_train = df_y[dataset_assignment <= training_set_size].values.flatten()\n",
    "\n",
    "X_test = df_X[dataset_assignment > training_set_size].values\n",
    "y_test = df_y[dataset_assignment > training_set_size].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб градієнтний спуск швидше збігався, нормалізуємо навчальну вибірку так, щоб кожна ознака мала $\\mu = 0, \\sigma = 1$:\n",
    "\n",
    "$ x' = \\frac{x - \\bar{x}}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.496507Z",
     "start_time": "2019-02-17T20:44:15.493353Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_means = np.average(X_train, axis=0)\n",
    "feature_sigmas = np.std(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.500821Z",
     "start_time": "2019-02-17T20:44:15.498264Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - feature_means) / feature_sigmas\n",
    "X_test = (X_test - feature_means) / feature_sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Додаємо уявну ознаку $x_0 = 1$ (intercept term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.511691Z",
     "start_time": "2019-02-17T20:44:15.506769Z"
    }
   },
   "outputs": [],
   "source": [
    "if not np.all(X_train[:, 0] == 1):\n",
    "    X_train = np.insert(X_train, 0, values=1, axis=1)\n",
    "    \n",
    "if not np.all(X_test[:, 0] == 1):\n",
    "    X_test = np.insert(X_test, 0, values=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.521241Z",
     "start_time": "2019-02-17T20:44:15.516713Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train:  (741, 9)\n",
      "y train:  (741,)\n",
      "\n",
      "X test:   (188, 9)\n",
      "y test:   (188,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train: \", X_train.shape)\n",
    "print(\"y train: \", y_train.shape)\n",
    "print()\n",
    "print(\"X test:  \", X_test.shape)\n",
    "print(\"y test:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделювання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію гіпотези лінійної регресії в матричній формі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.526199Z",
     "start_time": "2019-02-17T20:44:15.523070Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_linear(theta, X):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Compute the hypothesis function for linear regression.\n",
    "    return np.dot(X,theta)\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію зважування всіх навчальних прикладів $x^{(i)}$, якщо нам дана точка передбачення $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.532531Z",
     "start_time": "2019-02-17T20:44:15.528616Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_example_weights(X, x_pred, tau):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Compute the weight for each example, given the\n",
    "    # prediction point (x_pred).\n",
    "\n",
    "    # ====================================================\n",
    "    \n",
    "    return np.exp(-1*np.sum((X - x_pred)**2, axis=1) / (2*tau**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте функцію втрат зваженої лінійної регресії. Подумайте, як обчислити цей вираз відразу в матричному вигляді."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following matrix formula:\n",
    "$$\\frac{1}{m}W(X\\theta-y)^T(X\\theta-y),$$\n",
    "\n",
    "where $m$ is the number of objects, $W=diag(\\omega^{(i)})$. We can skip fraction term as it will scale down our gradient, and consequently slow down iterative process. We have learning rate for this purpose.\n",
    "In code this formula was implemented taking into account how numpy treats 1-dimensional arrays in multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.538007Z",
     "start_time": "2019-02-17T20:44:15.534690Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_function(theta, X, y, weights):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the currently learned model weights (theta),\n",
    "    # compute the overall loss on the training set (X),\n",
    "    # taking the weights into account.\n",
    "    \n",
    "    return np.dot(weights, (predict_linear(theta, X) - y)**2) / (2*y.shape[0])\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте обчислення градієнта функції втрат зваженої лінійної регресії. Подумайте, як обчислити цей вираз відразу в матричному вигляді."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following matrix formula:\n",
    "$$\\frac{1}{m}X^TW(X\\theta-y),$$\n",
    "\n",
    "where $m$ is the number of objects, $W=diag(\\omega^{(i)})$. We can skip fraction term as it will scale down our gradient, and consequently slow down iterative process. We have learning rate for this purpose.\n",
    "In code this formula was implemented taking into account how numpy treats 1-dimensional arrays in multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.544019Z",
     "start_time": "2019-02-17T20:44:15.540350Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_function_gradient(theta, X, y, weights):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the currently learned model weights (theta),\n",
    "    # compute the gradient of the cost function on the\n",
    "    # training set (X), taking the weights into account.\n",
    "    return np.multiply(weights, predict_linear(theta, X) - y).dot(X) #/ (y.shape[0])\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізуйте один крок градієнтного спуску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.549029Z",
     "start_time": "2019-02-17T20:44:15.545965Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_model_weights(theta, learning_rate, cost_gradient):\n",
    "    # =============== TODO: Your code here ===============\n",
    "    # Given the learning rate and the gradient of the\n",
    "    # cost function, take one gradient descent step and\n",
    "    # return the updated vector theta.   \n",
    "    return (theta - learning_rate*cost_gradient)\n",
    "    # ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Навчаємо модель:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.557115Z",
     "start_time": "2019-02-17T20:44:15.551244Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, weights, loss_fun, grad_fun, learning_rate, convergence_threshold, max_iters, verbose=False):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        loss = loss_fun(theta, X, y, weights)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Iteration: {0:3} Loss: {1}\".format(i + 1, loss))\n",
    "\n",
    "        if len(losses) > 2 and np.abs(losses[-1] - losses[-2]) <= convergence_threshold:\n",
    "            break\n",
    "        \n",
    "        grad = grad_fun(theta, X, y, weights)\n",
    "        theta = update_model_weights(theta, learning_rate, grad)\n",
    "        \n",
    "    return theta, np.array(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Передбачення нових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.565321Z",
     "start_time": "2019-02-17T20:44:15.559584Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_weighted_linear(X, y, x_pred, verbose=False):\n",
    "    weights = get_example_weights(X, x_pred, tau=0.1)\n",
    "    theta, losses = gradient_descent(\n",
    "        X,\n",
    "        y,\n",
    "        weights,\n",
    "        loss_fun=cost_function,\n",
    "        grad_fun=cost_function_gradient,\n",
    "        learning_rate=0.005,\n",
    "        convergence_threshold=0.0001,\n",
    "        max_iters=500,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    return predict_linear(theta, x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.569800Z",
     "start_time": "2019-02-17T20:44:15.567128Z"
    }
   },
   "outputs": [],
   "source": [
    "x_pred = X_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.576664Z",
     "start_time": "2019-02-17T20:44:15.572028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        , -0.08961014,  0.81445108, -0.42640143,  3.3999003 ,\n",
       "       -0.87183428, -0.38579426, -0.23249528, -0.42640143])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:15.793573Z",
     "start_time": "2019-02-17T20:44:15.578457Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:   1 Loss: 2051.275762424122\n",
      "Iteration:   2 Loss: 1513.8075453393894\n",
      "Iteration:   3 Loss: 1121.566141208521\n",
      "Iteration:   4 Loss: 835.3104813807898\n",
      "Iteration:   5 Loss: 626.4026457393462\n",
      "Iteration:   6 Loss: 473.9428347420584\n",
      "Iteration:   7 Loss: 362.67848747951024\n",
      "Iteration:   8 Loss: 281.47836731823753\n",
      "Iteration:   9 Loss: 222.21895783853518\n",
      "Iteration:  10 Loss: 178.9717606000031\n",
      "Iteration:  11 Loss: 147.410189437005\n",
      "Iteration:  12 Loss: 124.37672511648802\n",
      "Iteration:  13 Loss: 107.56702714333434\n",
      "Iteration:  14 Loss: 95.29940026075583\n",
      "Iteration:  15 Loss: 86.3465523464754\n",
      "Iteration:  16 Loss: 79.81281223336279\n",
      "Iteration:  17 Loss: 75.04452393759315\n",
      "Iteration:  18 Loss: 71.56465284995897\n",
      "Iteration:  19 Loss: 69.02506168722132\n",
      "Iteration:  20 Loss: 67.17168173897295\n",
      "Iteration:  21 Loss: 65.8190950315699\n",
      "Iteration:  22 Loss: 64.83198452854964\n",
      "Iteration:  23 Loss: 64.1115965870091\n",
      "Iteration:  24 Loss: 63.5858613313323\n",
      "Iteration:  25 Loss: 63.20218255525631\n",
      "Iteration:  26 Loss: 62.92217583131278\n",
      "Iteration:  27 Loss: 62.717828411496484\n",
      "Iteration:  28 Loss: 62.568696743498265\n",
      "Iteration:  29 Loss: 62.45986123317697\n",
      "Iteration:  30 Loss: 62.380433641249596\n",
      "Iteration:  31 Loss: 62.32246778945132\n",
      "Iteration:  32 Loss: 62.2801645997701\n",
      "Iteration:  33 Loss: 62.24929193637043\n",
      "Iteration:  34 Loss: 62.22676120936045\n",
      "Iteration:  35 Loss: 62.210318382506195\n",
      "Iteration:  36 Loss: 62.198318472329206\n",
      "Iteration:  37 Loss: 62.18956097876488\n",
      "Iteration:  38 Loss: 62.18316978334518\n",
      "Iteration:  39 Loss: 62.17850549954057\n",
      "Iteration:  40 Loss: 62.17510150651256\n",
      "Iteration:  41 Loss: 62.172617266891585\n",
      "Iteration:  42 Loss: 62.170804258343175\n",
      "Iteration:  43 Loss: 62.16948111060899\n",
      "Iteration:  44 Loss: 62.1685154606533\n",
      "Iteration:  45 Loss: 62.16781071064699\n",
      "Iteration:  46 Loss: 62.167296364015726\n",
      "Iteration:  47 Loss: 62.16692097274004\n",
      "Iteration:  48 Loss: 62.166646990332964\n",
      "Iteration:  49 Loss: 62.16644701557097\n",
      "Iteration:  50 Loss: 62.166301051188995\n",
      "Iteration:  51 Loss: 62.16619450329094\n",
      "Iteration:  52 Loss: 62.166116721330184\n"
     ]
    }
   ],
   "source": [
    "predicted = predict_weighted_linear(X_train, y_train, x_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцінимо, наскільки модель помиляється на тестовій вибірці:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:16.926486Z",
     "start_time": "2019-02-17T20:44:15.795194Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = np.array([predict_weighted_linear(X_test, y_test, X_test[i]) for i in range(len(y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:16.932289Z",
     "start_time": "2019-02-17T20:44:16.928527Z"
    }
   },
   "outputs": [],
   "source": [
    "df_residuals = pd.DataFrame(y_test - y_test_pred, columns=[\"residual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:18.244104Z",
     "start_time": "2019-02-17T20:44:16.934361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Error Distribution')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df_residuals.plot.bar(figsize=(10, 5))\n",
    "ax.legend().remove()\n",
    "ax.get_xaxis().set(ticklabels=[])\n",
    "ax.set(xlabel=\"Example #\")\n",
    "ax.set(ylabel=\"Prediction Error, $\")\n",
    "ax.set(title=\"Residuals\")\n",
    "\n",
    "bins = np.arange(-3000, 3001, 100)\n",
    "ticks = np.arange(-3000, 3001, 500)\n",
    "\n",
    "ax = df_residuals.hist(bins=bins, figsize=(10, 5))[0][0]\n",
    "ax.set(xticks=ticks)\n",
    "ax.set(xlabel=\"Prediction Error, $\")\n",
    "ax.set(ylabel=\"Frequency\")\n",
    "ax.set(title=\"Error Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестування"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустіть комірку нижче, щоб перевірити правильність вашого коду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T20:44:18.259255Z",
     "start_time": "2019-02-17T20:44:18.246379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/unittest.status+json": {
       "color": "yellow",
       "message": "",
       "previous": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/unittest.status+json": {
       "color": "lightgreen",
       "message": "............\n----------------------------------------------------------------------\nRan 12 tests in 0.002s\n\nOK\n",
       "previous": 0
      },
      "text/plain": [
       "Success"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=12 errors=0 failures=0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%unittest_main\n",
    "\n",
    "class WLRTests(unittest.TestCase):\n",
    "\n",
    "    x = np.array([1, -0.5, 3, 1])\n",
    "    X = np.array([\n",
    "        [1, -0.5, 3, 1],\n",
    "        [2, 8, -0.33, 5],\n",
    "        [0, 0, 0, 0]\n",
    "    ])\n",
    "    y = np.array([40, 100, 12])\n",
    "    theta = np.array([2, 5, 7, 9])\n",
    "    eps = 0.001\n",
    "\n",
    "    def assertFloatEquals(self, a, b):\n",
    "        self.assertTrue(np.abs(a - b) < self.eps)\n",
    "    \n",
    "    def assertArrayEquals(self, a, b):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        self.assertEqual(a.shape, b.shape)\n",
    "        self.assertTrue(np.all(np.abs(a - b) < self.eps))\n",
    "    \n",
    "    def test_predict_linear_should_compute_correct_prediction_for_1_example(self):\n",
    "        expected = 29.5\n",
    "        actual = predict_linear(self.theta, self.x)\n",
    "        self.assertEqual(actual, expected)\n",
    "    \n",
    "    def test_predict_linear_should_compute_correct_predictions_for_multiple_examples(self):\n",
    "        expected = [29.5, 86.69, 0]\n",
    "        actual = (predict_linear(self.theta, self.X))\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_get_example_weights_should_return_properly_shaped_vector(self):\n",
    "        weights = get_example_weights(self.X, self.x, tau=5)\n",
    "        self.assertTrue(weights.shape[0] == self.X.shape[0])\n",
    "    \n",
    "    def test_get_example_weights_should_compute_correct_weights(self):\n",
    "        expected = [1.000, 0.134, 0.798]\n",
    "        actual = get_example_weights(self.X, self.x, tau=5)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_cost_function_should_compute_correct_cost_unweighted(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        expected = 71.901\n",
    "        actual = cost_function(self.theta, self.X, self.y, weights)\n",
    "        self.assertFloatEquals(actual, expected)\n",
    "    \n",
    "    def test_cost_function_should_compute_correct_cost_weighted(self):\n",
    "        weights = np.array([0.5, 0.1, 0.28])\n",
    "        expected = 18.860\n",
    "        actual = cost_function(self.theta, self.X, self.y, weights)\n",
    "        self.assertFloatEquals(actual, expected)\n",
    "\n",
    "    def test_cost_gradient_should_return_properly_shaped_vector(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        grad = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertTrue(grad.shape == self.theta.shape)\n",
    "        \n",
    "    def test_cost_gradient_should_compute_correct_gradient_unweighted(self):\n",
    "        weights = np.ones(self.X.shape[0])\n",
    "        expected = [-37.12, -101.23, -27.108, -77.05]\n",
    "        actual = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_cost_gradient_should_compute_correct_gradient_weighted(self):\n",
    "        weights = np.array([0.5, 0.1, 0.28])\n",
    "        expected = [-7.912, -8.023, -15.311, -11.905]\n",
    "        actual = cost_function_gradient(self.theta, self.X, self.y, weights)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_update_model_weights_should_not_update_when_gradient_is_zero(self):\n",
    "        grad = np.zeros(self.theta.shape[0])\n",
    "        theta_new = update_model_weights(self.theta, learning_rate=1, cost_gradient=grad)\n",
    "        self.assertArrayEquals(theta_new, self.theta)\n",
    "    \n",
    "    def test_update_model_weights_should_update_with_complete_gradient_if_learning_rate_is_one(self):\n",
    "        grad = np.array([1.35, -0.89, 0.16, 0.98])\n",
    "        expected = [0.65, 5.89, 6.84, 8.02]\n",
    "        actual = update_model_weights(self.theta, learning_rate=1, cost_gradient=grad)\n",
    "        self.assertArrayEquals(actual, expected)\n",
    "    \n",
    "    def test_update_model_weights_should_take_learning_rate_into_account(self):\n",
    "        grad = np.array([1.35, -0.89, 0.16, 0.98])\n",
    "        expected = [1.730, 5.178, 6.968, 8.804]\n",
    "        actual = update_model_weights(self.theta, learning_rate=0.2, cost_gradient=grad)\n",
    "        self.assertArrayEquals(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
